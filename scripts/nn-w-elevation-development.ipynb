{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf98f83",
   "metadata": {},
   "source": [
    "This notebook is for development! Use it to try out new strategies :) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d6bdc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Imports:</b> Common imports for NumPy, MatplotLib, Pandas, and OS </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bee40cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import for data generation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e403c29",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>ML Imports:</b> Imports to execute RNN model for sequential data </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8dd7964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "from pyspark import SparkContext\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdda552",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>nn_train_test() function:</b> \n",
    "    \n",
    "This function creates the train and test sets a little differently. Instead of using pca to reduce dimensionality, it keeps all the data in anticipation of the Neural Net Framework to deal with filtering through it. The d variable allows you to discretize the grid down further as well.\n",
    "    \n",
    "    path --> path to the repository with all your .npy file\n",
    "    n_future --> number of future days of fire you want to predict (will be 1 for us)\n",
    "    n_comp --> Doesn't do anything right now\n",
    "    n_past --> number of past days you want to consider (we can experiment with this)\n",
    "    d --> The size of the discretized fires you want (i.e. d= 32, returns subset of sequences for 32x32 grids)\n",
    "    \n",
    "Outputs:\n",
    "    \n",
    "    input_dim is set to a 1-D array of 256 ^ 2 for now! \n",
    "    x_train --> x_train in format (batch_size, timesteps, input_dim)\n",
    "    y_train --> training data in format (batch_size, input_dim)\n",
    "    pca_array -->  Nothing\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394bc806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnUtils\n",
    "from nnUtils import nn_train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabcd696",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>RNN Inputs:</b> \n",
    "We are declaring below that the number of future days we want to predict is 1, and we can vary the number of past days\n",
    "    we want to predict (I have the default as 3 for now)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2316df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_future = 1\n",
    "n_comp = 10\n",
    "n_past = 3\n",
    "discretization_amount = d = 64 # 256 means we keep the whole fire grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f96c0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Input Data for Training:</b> \n",
    "    Below, we get the input data from December 2018! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8183015d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "# We are suppressing print statements and warning messages w/ above line\n",
    "path = \"C:\\\\Users\\\\nico\\\\Desktop\\\\Stanford\\\\OneDrive - Stanford\\\\Courses\\\\CS229\\\\finalproject\\\\data\\\\United_States_Fires\\\\United_States_2018_Fires\\\\jan\\\\storage\"\n",
    "months = ['feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug' ,'sep', 'oct', 'nov', 'dec']\n",
    "x_train, y_train = nn_train_test(path, n_past = n_past, n_comp = n_comp, n_future = n_future, d = d)\n",
    "for month in months:\n",
    "    path = \"C:\\\\Users\\\\nico\\\\Desktop\\\\Stanford\\\\OneDrive - Stanford\\\\Courses\\\\CS229\\\\finalproject\\\\data\\\\United_States_Fires\\\\United_States_2018_Fires\\\\{mon}\\\\storage\".format(mon = month)\n",
    "    x, y  = nn_train_test(path, n_past = n_past, n_comp = n_comp, n_future = n_future, d = d)\n",
    "    if len(x) == 0:\n",
    "        continue\n",
    "    x_train = np.vstack((x_train, x))\n",
    "    y_train = np.vstack((y_train, y))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc87cba",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Check:</b> \n",
    "    Check the shape of your x_train and y_train data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64eeca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4952aace",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    This follows the model in https://towardsdatascience.com/wildfire-spreading-modeling-in-alberta-canada-a-trial-using-a-neural-network-with-convlstm-cells-81c1a9f7d410. Their GitHub is at the bottom of the page \n",
    "    \n",
    "<b>Train your RNN:</b> Train your RNN using the training data.\n",
    "    \n",
    "    You might notice a lot of arbitrary values here (these are things we will want to change and test)\n",
    "    - Dropout: High dropout leads to more generalization. Low dropout takes advantage of more data but overfits more easily\n",
    "    - # of hidden layers: Right now, there are 2 hidden layers (+ 1 at the end). We can change this\n",
    "    - # units at hidden layers: Right now, units decrease by 1 at each hidden layer. This is arbitrary and can be changed\n",
    "    - optimizer --> 'adam' works but I don't know what it does\n",
    "    - epochs --> We can raise this above 1 but I don't notice that changing much when I have done so\n",
    "    - batch_size --> Higher batch size leads to more generalization\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79dffe7",
   "metadata": {},
   "source": [
    "Reshape your data as needed for the ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b198b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffler = np.random.permutation(len(x_train))\n",
    "x_train = x_train[shuffler]\n",
    "y_train = y_train[shuffler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0d676cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11844/4010326000.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdropout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"valid\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"sigmoid\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPool2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m    658\u001b[0m                \u001b[0mbias_constraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m                **kwargs):\n\u001b[1;32m--> 660\u001b[1;33m     super(Conv2D, self).__init__(\n\u001b[0m\u001b[0;32m    661\u001b[0m         \u001b[0mrank\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, conv_op, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m                \u001b[0mconv_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m                **kwargs):\n\u001b[1;32m--> 126\u001b[1;33m     super(Conv, self).__init__(\n\u001b[0m\u001b[0;32m    127\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m         \u001b[0mbatch_input_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_shape'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_input_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_input_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "# No need to run this if you are loading a model\n",
    "regressor = Sequential()\n",
    "\n",
    "dropout = 0.0\n",
    "\n",
    "regressor.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = (3,3), padding = \"valid\", activation = \"sigmoid\", input_shape = (1)))\n",
    "\n",
    "regressor.add(tf.keras.layers.MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "regressor.add(tf.keras.layers.Flatten())\n",
    "\n",
    "regressor.add(tf.keras.layers.Dense(units = 4*64, activation = 'relu'))\n",
    "\n",
    "regressor.add(tf.keras.layers.Dense(units = 8*64, activation = 'relu'))\n",
    "\n",
    "regressor.add(tf.keras.layers.Dense(units = 16*64, activation = 'relu'))\n",
    "\n",
    "regressor.add(tf.keras.layers.Dense(units = 1, activation = 'relu'))\n",
    "\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience = 2),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='1D-output-256-2.h5'),   \n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['acc'])\n",
    "\n",
    "history = regressor.fit(x_train, y_train, epochs = 100, batch_size = 10, validation_split = 0.2, callbacks = my_callbacks)\n",
    "\n",
    "import pickle\n",
    "with open(\"C:\\\\Users\\\\nico\\\\Desktop\\\\Stanford\\\\OneDrive - Stanford\\\\Courses\\\\CS229\\\\finalproject\\\\scripts\\\\history.pkl\",\"w\") as f:\n",
    "    f.write(str(history.history))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5d29b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dcb5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6352174",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7e80ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8560, 64, 64, 5), (8560, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array([np.sum(y) for y in y_train])\n",
    "x_train, y_train = x_train.reshape((int(x_train.shape[0]), d, d, 5)), y_train.reshape((int(y_train.shape[0]), 1))\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d68ad646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "685/685 [==============================] - 22s 28ms/step - loss: 160951.8906 - acc: 0.0213 - val_loss: 156857.7344 - val_acc: 0.0193\n",
      "Epoch 2/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 147985.8906 - acc: 0.0194 - val_loss: 156431.2812 - val_acc: 0.0222\n",
      "Epoch 3/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 144759.9219 - acc: 0.0450 - val_loss: 148843.6094 - val_acc: 0.4714\n",
      "Epoch 4/100\n",
      "685/685 [==============================] - 16s 24ms/step - loss: 143364.8906 - acc: 0.0258 - val_loss: 154478.8750 - val_acc: 0.0193\n",
      "Epoch 5/100\n",
      "685/685 [==============================] - 18s 27ms/step - loss: 142208.1719 - acc: 0.0209 - val_loss: 149454.7656 - val_acc: 0.0187\n",
      "Epoch 6/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 139956.6094 - acc: 0.0305 - val_loss: 147782.2344 - val_acc: 0.0193\n",
      "Epoch 7/100\n",
      "685/685 [==============================] - 19s 28ms/step - loss: 140992.2188 - acc: 0.0384 - val_loss: 152285.3750 - val_acc: 0.0193\n",
      "Epoch 8/100\n",
      "685/685 [==============================] - 20s 29ms/step - loss: 137490.3438 - acc: 0.0640 - val_loss: 150124.3438 - val_acc: 0.0187\n",
      "Epoch 9/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 136283.9688 - acc: 0.0321 - val_loss: 147673.9688 - val_acc: 0.0193\n",
      "Epoch 10/100\n",
      "685/685 [==============================] - 18s 26ms/step - loss: 137064.7344 - acc: 0.0212 - val_loss: 148637.2188 - val_acc: 0.0193\n",
      "Epoch 11/100\n",
      "685/685 [==============================] - 17s 24ms/step - loss: 136402.2500 - acc: 0.0210 - val_loss: 147695.4844 - val_acc: 0.0193\n",
      "Epoch 12/100\n",
      "685/685 [==============================] - 18s 27ms/step - loss: 134072.9375 - acc: 0.0210 - val_loss: 153344.8906 - val_acc: 0.0204\n",
      "Epoch 13/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 132014.5938 - acc: 0.0520 - val_loss: 160802.3594 - val_acc: 0.6040\n",
      "Epoch 14/100\n",
      "685/685 [==============================] - 19s 28ms/step - loss: 132567.4375 - acc: 0.0429 - val_loss: 148334.1719 - val_acc: 0.0193\n",
      "Epoch 15/100\n",
      "685/685 [==============================] - 19s 28ms/step - loss: 129251.7969 - acc: 0.0260 - val_loss: 149687.3438 - val_acc: 0.0193\n",
      "Epoch 16/100\n",
      "685/685 [==============================] - 19s 28ms/step - loss: 127206.4609 - acc: 0.0209 - val_loss: 151860.9219 - val_acc: 0.0193\n",
      "Epoch 17/100\n",
      "685/685 [==============================] - 16s 24ms/step - loss: 120665.5547 - acc: 0.0212 - val_loss: 162151.1250 - val_acc: 0.0193\n",
      "Epoch 18/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 120312.3203 - acc: 0.0216 - val_loss: 156067.7812 - val_acc: 0.0193\n",
      "Epoch 19/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 120051.2812 - acc: 0.0521 - val_loss: 156909.7812 - val_acc: 0.0251\n",
      "Epoch 20/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 115086.0859 - acc: 0.0529 - val_loss: 154588.6875 - val_acc: 0.0199\n",
      "Epoch 21/100\n",
      "685/685 [==============================] - 18s 27ms/step - loss: 115264.4844 - acc: 0.0213 - val_loss: 161607.0781 - val_acc: 0.0199\n",
      "Epoch 22/100\n",
      "685/685 [==============================] - 19s 28ms/step - loss: 110343.5625 - acc: 0.0320 - val_loss: 157582.0312 - val_acc: 0.0537\n",
      "Epoch 23/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 105402.6094 - acc: 0.0314 - val_loss: 180403.1094 - val_acc: 0.0199\n",
      "Epoch 24/100\n",
      "685/685 [==============================] - 16s 24ms/step - loss: 101725.1875 - acc: 0.0247 - val_loss: 157914.0938 - val_acc: 0.0234\n",
      "Epoch 25/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 98040.7578 - acc: 0.0294 - val_loss: 168841.4062 - val_acc: 0.0193\n",
      "Epoch 26/100\n",
      "685/685 [==============================] - 18s 27ms/step - loss: 92324.3828 - acc: 0.0213 - val_loss: 158732.3594 - val_acc: 0.0193\n",
      "Epoch 27/100\n",
      "685/685 [==============================] - 18s 27ms/step - loss: 89024.9453 - acc: 0.0212 - val_loss: 161905.5156 - val_acc: 0.0193\n",
      "Epoch 28/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 83668.7812 - acc: 0.0213 - val_loss: 172989.5625 - val_acc: 0.0193\n",
      "Epoch 29/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 81857.3359 - acc: 0.0212 - val_loss: 160159.8906 - val_acc: 0.0199\n",
      "Epoch 30/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 77510.0859 - acc: 0.0218 - val_loss: 176077.2031 - val_acc: 0.0210\n",
      "Epoch 31/100\n",
      "685/685 [==============================] - 16s 23ms/step - loss: 80554.6016 - acc: 0.0261 - val_loss: 178205.5156 - val_acc: 0.0193\n",
      "Epoch 32/100\n",
      "685/685 [==============================] - 18s 27ms/step - loss: 74522.6875 - acc: 0.0213 - val_loss: 179105.4219 - val_acc: 0.0204\n",
      "Epoch 33/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 74878.3438 - acc: 0.0222 - val_loss: 160157.3594 - val_acc: 0.0204\n",
      "Epoch 34/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 75369.3516 - acc: 0.0256 - val_loss: 162742.3125 - val_acc: 0.0199\n",
      "Epoch 35/100\n",
      "685/685 [==============================] - 19s 28ms/step - loss: 68061.9297 - acc: 0.0216 - val_loss: 161823.3906 - val_acc: 0.0199\n",
      "Epoch 36/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 64494.4609 - acc: 0.0222 - val_loss: 162606.4375 - val_acc: 0.0216\n",
      "Epoch 37/100\n",
      "685/685 [==============================] - 18s 27ms/step - loss: 64660.6016 - acc: 0.0226 - val_loss: 170128.3750 - val_acc: 0.0234\n",
      "Epoch 38/100\n",
      "685/685 [==============================] - 16s 23ms/step - loss: 65554.4219 - acc: 0.0231 - val_loss: 161250.0000 - val_acc: 0.0193\n",
      "Epoch 39/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 62469.5469 - acc: 0.0226 - val_loss: 160224.4375 - val_acc: 0.0193\n",
      "Epoch 40/100\n",
      "685/685 [==============================] - 18s 27ms/step - loss: 60113.8359 - acc: 0.0222 - val_loss: 167195.4375 - val_acc: 0.0193\n",
      "Epoch 41/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 59558.2305 - acc: 0.0221 - val_loss: 171841.3281 - val_acc: 0.0216\n",
      "Epoch 42/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 67463.9219 - acc: 0.0396 - val_loss: 170671.7031 - val_acc: 0.0216\n",
      "Epoch 43/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 62457.5469 - acc: 0.0229 - val_loss: 168604.4688 - val_acc: 0.0193\n",
      "Epoch 44/100\n",
      "685/685 [==============================] - 18s 26ms/step - loss: 55298.6953 - acc: 0.0226 - val_loss: 169447.4062 - val_acc: 0.0239\n",
      "Epoch 45/100\n",
      "685/685 [==============================] - 17s 25ms/step - loss: 55571.2773 - acc: 0.0237 - val_loss: 165848.1875 - val_acc: 0.0234\n",
      "Epoch 46/100\n",
      "685/685 [==============================] - 18s 27ms/step - loss: 56009.8516 - acc: 0.0235 - val_loss: 171918.4062 - val_acc: 0.0263\n",
      "Epoch 47/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 56821.4531 - acc: 0.0248 - val_loss: 167541.5156 - val_acc: 0.0193\n",
      "Epoch 48/100\n",
      "685/685 [==============================] - 19s 27ms/step - loss: 55036.6836 - acc: 0.0223 - val_loss: 166857.6875 - val_acc: 0.0234\n",
      "Epoch 49/100\n",
      "685/685 [==============================] - 19s 28ms/step - loss: 52691.4297 - acc: 0.0251 - val_loss: 169470.0781 - val_acc: 0.0251\n",
      "Epoch 50/100\n",
      "487/685 [====================>.........] - ETA: 5s - loss: 54674.8438 - acc: 0.0230"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12208/1638238508.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# No need to run this if you are loading a model\n",
    "regressor = Sequential()\n",
    "\n",
    "dropout = 0.0\n",
    "\n",
    "#regressor.add(tf.keras.layers.Masking(mask_value=-9999,input_shape= x_train[0].shape)) \n",
    "regressor.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = (3,3), padding = \"valid\", activation = \"sigmoid\", input_shape = x_train[0].shape))\n",
    "\n",
    "regressor.add(tf.keras.layers.MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "regressor.add(tf.keras.layers.BatchNormalization(center=True, scale=True))\n",
    "\n",
    "regressor.add(tf.keras.layers.Flatten())\n",
    "\n",
    "regressor.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))\n",
    "\n",
    "regressor.add(tf.keras.layers.Dense(units = 64, activation = 'relu'))\n",
    "\n",
    "regressor.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "regressor.add(tf.keras.layers.Dense(units = 1, activation = 'relu'))\n",
    "\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience = 100),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='1D-output-64-{epoch}.h5'),   \n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['acc'])\n",
    "\n",
    "history = regressor.fit(x_train, y_train, epochs = 100, batch_size = 10, validation_split = 0.2, callbacks = my_callbacks)\n",
    "\n",
    "import pickle\n",
    "with open(\"C:\\\\Users\\\\nico\\\\Desktop\\\\Stanford\\\\OneDrive - Stanford\\\\Courses\\\\CS229\\\\finalproject\\\\scripts\\\\history.pkl\",\"w\") as f:\n",
    "    f.write(str(history.history))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f15012a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8560, 1, 64, 64, 5), (8560, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array([np.sum(y) for y in y_train])\n",
    "x_train, y_train = x_train.reshape((int(x_train.shape[0]), 1, d, d, 5)), y_train.reshape((int(y_train.shape[0]), 1))\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e201d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "# d = 64\n",
    "act = \"relu\"\n",
    "batch_normalization = True\n",
    "layersd = 1 #1\n",
    "layers2d = 1 #0\n",
    "pooling2d = 1\n",
    "layers4d = 2 #0\n",
    "pooling4d = 1\n",
    "pooling = True ## DO NOT CHANGE\n",
    "dropout = 0.25\n",
    "learning_rate = .01\n",
    "epochs = 1000\n",
    "dense = 1\n",
    "train_range = range(0, len(x_train)) #range(0,50)#\n",
    "t = len(train_range)\n",
    "\n",
    "for i in range(layersd):\n",
    "    regressor.add(tf.keras.layers.Conv3D(filters = d, kernel_size = (1,3,3), padding = \"valid\", activation = \"sigmoid\", input_shape = x_train[0].shape))\n",
    "\n",
    "if pooling and layersd:\n",
    "    regressor.add(tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2), padding=\"valid\"))\n",
    "\n",
    "if batch_normalization and layersd:\n",
    "    regressor.add(tf.keras.layers.BatchNormalization(center=True, scale=True))\n",
    "\n",
    "if layersd:\n",
    "    regressor.add(Dropout(dropout))\n",
    "\n",
    "for i in range(layers2d):\n",
    "    regressor.add(tf.keras.layers.Conv3D(filters = d*2, kernel_size = (1,3,3), padding = \"valid\", activation = act))\n",
    "\n",
    "if batch_normalization and layers2d:\n",
    "    regressor.add(tf.keras.layers.BatchNormalization(center=True, scale=True))\n",
    "\n",
    "\n",
    "for i in range(layers4d):\n",
    "    regressor.add(tf.keras.layers.Conv3D(filters = d*4, kernel_size = (1,3,3), padding = \"valid\", activation = act))\n",
    "\n",
    "\n",
    "for i in range(layers4d):\n",
    "    regressor.add(tf.keras.layers.Conv3D(filters = d*4, kernel_size = (1,3,3), padding = \"valid\", activation = act))\n",
    "\n",
    "if (pooling and layers4d) or pooling4d:\n",
    "    regressor.add(tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2), padding=\"valid\"))\n",
    "\n",
    "if batch_normalization and layers4d:\n",
    "    regressor.add(tf.keras.layers.BatchNormalization(center=True, scale=True))\n",
    "\n",
    "regressor.add(tf.keras.layers.Flatten())\n",
    "\n",
    "for i in range(dense):\n",
    "    regressor.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "#\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience = 5),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='1D-output.h5'),   \n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "regressor.compile(optimizer = opt, loss = 'mse', metrics = ['acc'])\n",
    "\n",
    "regressor.fit(x_train[train_range].reshape(t, 1, d, d, 5), y_train[train_range].reshape((t, 1)), epochs = epochs, batch_size = 1, callbacks = my_callbacks, validation_split = 0.2)\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cda16e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = load_model('1D-output-256.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031b80cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(b), np.sum(p), np.sum(y_train[38])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_train.reshape((x_train.shape[0],5, 64, 64))\n",
    "predict_test = regressor.predict(x_train[21].reshape((1, d, d, 5)))\n",
    "b = predict_test\n",
    "plt.matshow(b.reshape((64,64)))\n",
    "plt.show()\n",
    "predict_test = regressor.predict(x_train[22].reshape((1, d, d, 5)))\n",
    "p = predict_test\n",
    "print(\"X\")\n",
    "plt.matshow(x[22][0])\n",
    "plt.matshow(x[22][1])\n",
    "plt.matshow(x[22][2])\n",
    "plt.show()\n",
    "plt.matshow(p.reshape((64,64)))\n",
    "plt.show()\n",
    "plt.matshow(y_train[22].reshape((64,64)))\n",
    "predict_test = regressor.predict(x_train[159].reshape((1, 1, d, d, 4)))\n",
    "p = predict_test\n",
    "plt.matshow(p.reshape((64,64)))\n",
    "plt.show()\n",
    "plt.matshow(y_train[159].reshape((64,64)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f375a9c9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "This follows the general layout of https://keras.io/examples/vision/conv_lstm/. I haven't had much success with it\n",
    "    \n",
    "<b>Train your RNN:</b> Train your RNN using the training data.\n",
    "    \n",
    "    You might notice a lot of arbitrary values here (these are things we will want to change and test)\n",
    "    - Dropout: High dropout leads to more generalization. Low dropout takes advantage of more data but overfits more easily\n",
    "    - # of hidden layers: Right now, there are 2 hidden layers (+ 1 at the end). We can change this\n",
    "    - # units at hidden layers: Right now, units decrease by 1 at each hidden layer. This is arbitrary and can be changed\n",
    "    - optimizer --> 'adam' works but I don't know what it does\n",
    "    - epochs --> We can raise this above 1 but I don't notice that changing much when I have done so\n",
    "    - batch_size --> Higher batch size leads to more generalization\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bef725",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Load pre-trained model:</b> \n",
    "    If you want to load a model instead, use this\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8286357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model_name = '1D-output-64-11.h5' ## CHANGE THIS (e.g. 'my_model') ##\n",
    "regressor = load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5161273b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Save pre-trained model:</b> \n",
    "    If you want to save a model instead, use this\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9001ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '1d-2018-output-10-44.h5'## CHANGE THIS (e.g. 'my_model') ##\n",
    "regressor.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ff5d36",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Input Data for Testing:</b> \n",
    "    Below, we get the input data from March 2018! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b24f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "path = path = \"C:\\\\Users\\\\nico\\\\Desktop\\\\Stanford\\\\OneDrive - Stanford\\\\Courses\\\\CS229\\\\finalproject\\\\data\\\\United_States_Fires\\\\United_States_2017_Fires\\\\dec\\\\storage\"\n",
    "x_test, y_test  = nn_train_test(path, n_past = n_past, n_comp = n_comp, n_future = n_future, d = d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d8c129",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Check:</b> I've noticed the first dimensions of these sometimes these don't match. They should.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8e42b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = x_test.reshape((x_test.shape[0], 1, d, d, 5)), y_test.reshape((int(y_test.shape[0]), d, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8378a094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7008, 64, 64, 5), (7008, 1))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.array([np.sum(y) for y in y_test])\n",
    "x_test, y_test = x_test.reshape((int(x_test.shape[0]),d, d, 5)), y_test.reshape((int(y_test.shape[0]), 1))\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d037bb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b> Predict Step:</b> This makes your predictions using your model and reshapes them into a list of 2D arrays\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2968513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = regressor.predict(x_test)\n",
    "p = predict_test\n",
    "shape = predict_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848dc4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(x_test[500:, :, :, 0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e61cbbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(725389.8, 773668.0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(p), np.sum(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9909de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = regressor.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2339e785",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14992/269099716.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'blue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'red'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(y_train[0:100], 'blue')\n",
    "plt.plot(predict_train[0:100], 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cd3e8a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1568afad700>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test, 'blue')\n",
    "plt.plot(p, 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c4416",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train, 'blue')\n",
    "plt.plot(predict_train, 'red')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
