{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d41e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import for data generation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b20f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_21659081 = np.load(\"C:\\\\Users\\\\nico\\\\Desktop\\\\Stanford\\\\OneDrive - Stanford\\\\Courses\\\\CS229\\\\finalproject\\\\data\\\\United_States_Fires\\\\United_States_2019_Fires\\\\apr\\\\multi_day\\\\21659081.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c1145ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = []\n",
    "y_train_list = []\n",
    "n_future = 1\n",
    "n_past = 3\n",
    "\n",
    "def nn_train_test(path, n_future, n_past):\n",
    "    for file in os.listdir(r\"{path}\".format(path = path)):\n",
    "        if os.path.getsize(\"{path}\\\\{file}\".format(path = path, file = file)) < 100000:\n",
    "            continue\n",
    "\n",
    "        training_fire = np.load(\"{path}\\\\{file}\".format(path = path, file = file))\n",
    "        shape = np.array(training_fire.shape) \n",
    "\n",
    "        if shape[0] < n_past + n_future:\n",
    "            continue\n",
    "\n",
    "        standard_fire = np.zeros((len(training_fire), 256, 256))    \n",
    "        if shape[1] > 255 or shape[2] > 255:\n",
    "            standard_fire[:shape[0], :min(256, shape[1]), :min(256, shape[2])] = training_fire[:, :256, :256]\n",
    "        else: \n",
    "            standard_fire[:shape[0], :shape[1], :shape[2]] = training_fire\n",
    "\n",
    "        x_train = np.zeros((n_past, 256, 256))\n",
    "        y_train = np.zeros((256, 256))\n",
    "\n",
    "\n",
    "        for i in range(0 , len(standard_fire) - n_future - n_past + 1):\n",
    "            x_train_list.append(standard_fire[i : i + n_past])\n",
    "            y_train_list.append(standard_fire[i + n_past: i + n_past + n_future])\n",
    "\n",
    "    x_train = np.array(x_train_list)\n",
    "    y_train = np.array(y_train_list)\n",
    "\n",
    "    x_train = np.reshape(x_train, (1, x_train.shape[1], x_train.shape[0], x_train.shape[2], x_train.shape[3]))\n",
    "\n",
    "    y_train = np.reshape(y_train, (y_train.shape[0], y_train.shape[2], y_train.shape[3]))\n",
    "    \n",
    "    return x_train,y_train\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0488a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\nico\\\\Desktop\\\\Stanford\\\\OneDrive - Stanford\\\\Courses\\\\CS229\\\\finalproject\\\\data\\\\United_States_Fires\\\\United_States_2018_Fires\\\\feb\\\\multi_day\"\n",
    "x_train, y_train  = nn_train_test(path, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0f7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ad3d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b19d5e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "#sc =SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70126fa4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### WORKS! for the day before only though? \n",
    "regressor = Sequential()\n",
    "print(x_train.shape)\n",
    "dropout = 0.1\n",
    "regressor.add(tf.keras.layers.Bidirectional(LSTM(units=n_past, return_sequences=True, input_shape = x_train[0].shape)))\n",
    "regressor.add(Dropout(dropout))\n",
    "\n",
    "regressor.add(LSTM(units = n_past, return_sequences = True))\n",
    "regressor.add(Dropout(dropout))\n",
    "\n",
    "regressor.add(LSTM(units = n_past, return_sequences = True))\n",
    "regressor.add(Dropout(dropout))\n",
    "\n",
    "regressor.add(LSTM(units = n_past, return_sequences = True))\n",
    "regressor.add(Dropout(dropout))\n",
    "regressor.add(Dense(units = n_future, activation = 'linear'))\n",
    "\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['acc'])\n",
    "\n",
    "regressor.fit(x_train[0][2], y_train, epochs = 10, batch_size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57a1d605",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = []\n",
    "y_train_list = []\n",
    "n_future = 1\n",
    "n_past = 3\n",
    "\n",
    "def nn_train_test(path, n_future, n_past):\n",
    "    for file in os.listdir(r\"{path}\".format(path = path)):\n",
    "        if os.path.getsize(\"{path}\\\\{file}\".format(path = path, file = file)) < 100000:\n",
    "            continue\n",
    "\n",
    "        training_fire = np.load(\"{path}\\\\{file}\".format(path = path, file = file))\n",
    "        shape = np.array(training_fire.shape) \n",
    "\n",
    "        if shape[0] < n_past + n_future:\n",
    "            continue\n",
    "\n",
    "        standard_fire = np.zeros((len(training_fire), 256, 256))    \n",
    "        if shape[1] > 255 or shape[2] > 255:\n",
    "            standard_fire[:shape[0], :min(256, shape[1]), :min(256, shape[2])] = training_fire[:, :256, :256]\n",
    "        else: \n",
    "            standard_fire[:shape[0], :shape[1], :shape[2]] = training_fire\n",
    "        \n",
    "        standard_fire = np.reshape(standard_fire, (len(training_fire), 256**2))\n",
    "        pca = decomposition.PCA(n_components=1)\n",
    "        standard_fire = StandardScaler().fit_transform(standard_fire)\n",
    "        pca.fit_transform(standard_fire)\n",
    "        \n",
    "        \n",
    "        x_train = np.zeros((n_past, 256**2))\n",
    "        y_train = np.zeros((256**2))\n",
    "\n",
    "\n",
    "        for i in range(0 , len(standard_fire) - n_future - n_past + 1):\n",
    "            x_train_list.append(standard_fire[i : i + n_past])\n",
    "            y_train_list.append(standard_fire[i + n_past: i + n_past + n_future])\n",
    "\n",
    "    x_train = np.array(x_train_list)\n",
    "    y_train = np.array(y_train_list)\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0],  x_train.shape[2], x_train.shape[1]))\n",
    "\n",
    "    y_train = np.reshape(y_train, (y_train.shape[0], y_train.shape[2]))\n",
    "    \n",
    "    return x_train,y_train,standard_fire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea67411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\nico\\\\Desktop\\\\Stanford\\\\OneDrive - Stanford\\\\Courses\\\\CS229\\\\finalproject\\\\data\\\\United_States_Fires\\\\United_States_2018_Fires\\\\feb\\\\multi_day\"\n",
    "x_train, y_train,standard_fire  = nn_train_test(path, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9015bf81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 65536)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_fire.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d00db36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((193, 65536, 3), (193, 65536))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbd46739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bad480",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "print(x_train[0].shape)\n",
    "dropout = 0.1\n",
    "regressor.add(tf.keras.layers.Bidirectional(LSTM(units=n_past, return_sequences=True, input_shape = x_train[0].shape)))\n",
    "regressor.add(Dropout(dropout))\n",
    "\n",
    "regressor.add(LSTM(units = n_past, return_sequences = True))\n",
    "regressor.add(Dropout(dropout))\n",
    "'''\n",
    "regressor.add(LSTM(units = n_past, return_sequences = True))\n",
    "regressor.add(Dropout(dropout))\n",
    "\n",
    "regressor.add(LSTM(units = n_past, return_sequences = True))\n",
    "regressor.add(Dropout(dropout))\n",
    "'''\n",
    "regressor.add(Dense(units = n_future, activation = 'linear'))\n",
    "\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['acc'])\n",
    "\n",
    "regressor.fit(x_train, y_train, epochs = 10, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1dc269",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\nico\\\\Desktop\\\\Stanford\\\\OneDrive - Stanford\\\\Courses\\\\CS229\\\\finalproject\\\\data\\\\United_States_Fires\\\\United_States_2018_Fires\\\\mar\\\\multi_day\"\n",
    "x_test, y_test  = nn_train_test(path, 1, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb7396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#sc = MinMaxScaler(feature_range=(0,1))\n",
    "print(x_test.shape)\n",
    "\n",
    "#training_set_scaled = sc.fit_transform(x_train)\n",
    "\n",
    "predict_train = regressor.predict(x_test[0][0])\n",
    "\n",
    "\n",
    "#predict_train = np.reshape(predict_train, (7, 235))\n",
    "#sc = MinMaxScaler(feature_range=(0,1))\n",
    "#training_set_scaled = sc.fit_transform(predict_train)\n",
    "\n",
    "\n",
    "#predicted_fires = sc.inverse_transform(predict_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(predict_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df2457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#sc = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        if i == j:\n",
    "            continue\n",
    "        for k in range(4):\n",
    "            if i == k or j == k:\n",
    "                continue\n",
    "            for l in range(4):\n",
    "                if i == l or j == l or k == l:\n",
    "                    continue\n",
    "                else:\n",
    "                    try: \n",
    "\n",
    "                        x_test.reshape((x_test.shape[i], x_test.shape[j], x_test.shape[k], x_test.shape[l]))\n",
    "                        predict_test = regressor.predict(x_test)\n",
    "                        print(\"Ordering ({i}, {j}, {k}, {l}) IS feasible\".format(i=x_test.shape[i], j=x_test.shape[j], k=x_test.shape[k], l=x_test.shape[l]))\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(\"Ordering ({i}, {j}, {k}, {l}) not feasible\".format(i=x_test.shape[i], j=x_test.shape[j], k=x_test.shape[k], l=x_test.shape[l]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#training_set_scaled = sc.fit_transform(x_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#predict_test = np.reshape(predict_train, (7, 235))\n",
    "#sc = MinMaxScaler(feature_range=(0,1))\n",
    "#training_set_scaled = sc.fit_transform(predict_train)\n",
    "\n",
    "\n",
    "#predicted_fires = sc.inverse_transform(predict_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c463ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = ID_21659081\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "n_future = 1\n",
    "n_past = 5\n",
    "\n",
    "for i in range(0 , len(training_set) - n_future - n_past + 1):\n",
    "    x_train.append(training_set[i : i + n_past])\n",
    "    y_train.append(training_set[i + n_past: i + n_past + n_future])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[1], x_train.shape[0], x_train.shape[2], x_train.shape[3]))\n",
    "\n",
    "y_train = np.reshape(y_train, (y_train.shape[0], y_train.shape[2], y_train.shape[3]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
