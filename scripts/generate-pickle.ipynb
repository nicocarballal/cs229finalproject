{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "905557f9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Imports:</b> Common imports for NumPy, MatplotLib, Pandas, and OS along with some others </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f291ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset\n",
    "import numpy.ma as ma\n",
    "import numpy as np\n",
    "import pickle\n",
    "from simpledbf import Dbf5\n",
    "import shapefile\n",
    "import util\n",
    "from util import sort_by_id\n",
    "import single_fire\n",
    "from single_fire import *\n",
    "import datetime\n",
    "from datetime import date\n",
    "import math\n",
    "from math import floor, ceil\n",
    "import itertools\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from osgeo import osr, ogr, gdal\n",
    "import os\n",
    "#from mpl_toolkits.basemap import Basemap, addcyclic, shiftgrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4444a9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Imports:</b> Import your .nc dataset for temperature (Look at Notion on where to find this) </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb779cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_f = \"C:/Users/nicoc/Downloads/Complete_TAVG_Daily_LatLong1_2010.nc\"  # Your filename\n",
    "nc_fid = Dataset(nc_f, 'r')  # Dataset is the class behavior to open the file\n",
    "                    # and create an instance of the ncCDF4 class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2585d980",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Keys and dictionaries:</b> Get the keys and dimensions that are tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90271991",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nc_fid.variables.keys())\n",
    "print(\"-----\")\n",
    "print(nc_fid.dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499cd2cc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b> Variable Tracking:</b> Set variables to track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbde7279",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_fid.dimensions\n",
    "long = nc_fid.variables['longitude']\n",
    "lat = nc_fid.variables['latitude']\n",
    "tim = nc_fid.variables['day']\n",
    "day_num = nc_fid.variables['date_number']\n",
    "temp = nc_fid.variables['temperature']\n",
    "land_mask = nc_fid.variables['land_mask']\n",
    "clim = nc_fid.variables['climatology']\n",
    "day_of_year = nc_fid.variables['day_of_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7a40a1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Imports:</b> Let's look at the temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50599297",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Helper functions:</b> Defines some useful helper functions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4cd3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def world_to_pixel(geo_matrix, x, y):\n",
    "    \"\"\"\n",
    "    Uses a gdal geomatrix (gdal.GetGeoTransform()) to calculate\n",
    "    the pixel location of a geospatial coordinate\n",
    "    \"\"\"\n",
    "    ul_x= geo_matrix[0]\n",
    "    ul_y = geo_matrix[3]\n",
    "    x_dist = geo_matrix[1]\n",
    "    y_dist = geo_matrix[5]\n",
    "    pixel = int((x - ul_x) / x_dist)\n",
    "    line = -int((ul_y - y) / y_dist)\n",
    "    return pixel, line\n",
    "\n",
    "def get_elevation(ds, ds2, point, point2, transform, transform2, longitude, latitude):\n",
    "    '''\n",
    "    Get's elevation and topography from specific latitude and longitude\n",
    "    '''\n",
    "    point.AddPoint(latitude, longitude)\n",
    "    point.Transform(transform)\n",
    "    x, y = world_to_pixel(ds.GetGeoTransform(), point.GetX(), point.GetY())\n",
    "    data = np.array(ds.ReadAsArray(x, y, 1, 1))\n",
    "    try:\n",
    "        d = data[0][0]\n",
    "    except Exception as e:\n",
    "        print(\"There was an error\")\n",
    "        d = -9999\n",
    "    point2.AddPoint(latitude, longitude)\n",
    "    point2.Transform(transform2)\n",
    "    x2, y2 = world_to_pixel(ds2.GetGeoTransform(), point2.GetX(), point2.GetY())\n",
    "    data2 = np.array(ds2.ReadAsArray(x, y, 1, 1))\n",
    "    try:\n",
    "        d2 = data2[0][0]\n",
    "    except Exception as e:\n",
    "        print(\"Error 2\")\n",
    "        d2 = -9999\n",
    "    return d, d2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83019c19",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Main function:</b> Returns the elevation and topographical matrix based on the tifs for a fire range\n",
    "    Use get_elevationd and world_to_pixel\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elevation_func(tif_path, xRange, yRange, xDiff, yDiff):\n",
    "    \n",
    "    '''\n",
    "    Returns the elevation and topographical matrix based on the tifs for a fire range\n",
    "    Use get_elevationd and world_to_pixel\n",
    "    '''\n",
    "    \n",
    "    ds = gdal.Open(r'C:\\\\Users\\\\nicoc\\\\Downloads\\\\LF2016_Elev_200_CONUS\\\\Tif\\\\LC16_Elev_200.tif')\n",
    "    ds2 = gdal.Open(r'C:\\\\Users\\\\nicoc\\\\Downloads\\\\LF2019_FBFM13_200_CONUS\\\\Tif\\\\LC19_F13_200.tif')\n",
    "    \n",
    "    target = osr.SpatialReference(wkt=ds.GetProjection())\n",
    "    target2 = osr.SpatialReference(wkt = ds2.GetProjection())\n",
    "    source = osr.SpatialReference()\n",
    "    source2 = osr.SpatialReference()\n",
    "    source.ImportFromEPSG(4326)\n",
    "    source2.ImportFromEPSG(4326)\n",
    "    transform = osr.CoordinateTransformation(source, target)\n",
    "    transform2 = osr.CoordinateTransformation(source2, target2)\n",
    "    #41.3099° N, 122.3106° W\n",
    "    # 41.409767, -122.201180\n",
    "    \n",
    "    point = ogr.Geometry(ogr.wkbPoint)\n",
    "    point2 = ogr.Geometry(ogr.wkbPoint)\n",
    "    \n",
    "    xArray = np.arange(xRange[0], xRange[1] + xDiff, xDiff)\n",
    "    yArray = np.arange(yRange[0], yRange[1] + yDiff, yDiff)\n",
    "    xi = 0\n",
    "    top_matrix = np.zeros((xArray.shape[0], yArray.shape[0]))\n",
    "    elevation_matrix = np.zeros((xArray.shape[0], yArray.shape[0]))\n",
    "    for x in xArray:\n",
    "        yj = 0\n",
    "        for y in yArray:\n",
    "            elevation, top = get_elevation(ds, ds2, point, point2, transform, transform2, x, y)\n",
    "            elevation_matrix[xi][yj] = elevation\n",
    "            top_matrix[xi][yj] = top         \n",
    "            yj += 1\n",
    "        xi += 1\n",
    "    \n",
    "    return elevation_matrix, top_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc1820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARCHIVED: used to get elevation for given fire\n",
    "'''\n",
    "def elevation_func(tif_path, xRange, yRange, xDiff, yDiff):\n",
    "    \n",
    "    ds = gdal.Open(r'C:\\\\Users\\\\nicoc\\\\Downloads\\\\LF2016_Elev_200_CONUS\\\\Tif\\\\LC16_Elev_200.tif')\n",
    "    \n",
    "    target = osr.SpatialReference(wkt=ds.GetProjection())\n",
    "    source = osr.SpatialReference()\n",
    "    source.ImportFromEPSG(4326)\n",
    "    transform = osr.CoordinateTransformation(source, target)\n",
    "    #41.3099° N, 122.3106° W\n",
    "    # 41.409767, -122.201180\n",
    "    \n",
    "    point = ogr.Geometry(ogr.wkbPoint)\n",
    "    xArray = np.arange(xRange[0], xRange[1] + xDiff, xDiff)\n",
    "    yArray = np.arange(yRange[0], yRange[1] + yDiff, yDiff)\n",
    "    xi = 0\n",
    "    elevation_matrix = np.zeros((xArray.shape[0], yArray.shape[0]))\n",
    "    for x in xArray:\n",
    "        yj = 0\n",
    "        for y in yArray:\n",
    "            elevation_matrix[xi][yj] = get_elevation(ds, point, transform, x, y)\n",
    "            yj += 1\n",
    "        xi += 1\n",
    "    \n",
    "    return elevation_matrix\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ac58ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARCHIVED: Used to get elevation for particular point\n",
    "\"\"\"\n",
    "def get_elevation(ds, point, transform, longitude, latitude):\n",
    "    '''# Extract target reference from the tiff file\n",
    "    ds = gdal.Open(r'C:\\\\Users\\\\nicoc\\\\Downloads\\\\LF2016_Elev_200_CONUS\\\\Tif\\\\LC16_Elev_200.tif')\n",
    "    target = osr.SpatialReference(wkt=ds.GetProjection())\n",
    "\n",
    "    source = osr.SpatialReference()\n",
    "    source.ImportFromEPSG(4326)\n",
    "\n",
    "    transform = osr.CoordinateTransformation(source, target)\n",
    "    #41.3099° N, 122.3106° W\n",
    "    # 41.409767, -122.201180\n",
    "    point = ogr.Geometry(ogr.wkbPoint)\n",
    "    '''\n",
    "    point.AddPoint(latitude, longitude)\n",
    "    point.Transform(transform)\n",
    "    x, y = world_to_pixel(ds.GetGeoTransform(), point.GetX(), point.GetY())\n",
    "    data = np.array(ds.ReadAsArray(x, y, 1, 1))\n",
    "    try:\n",
    "        return data[0][0]\n",
    "    except Exception as e:\n",
    "        return -9999\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325ec852",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Main function:</b> Generates a pickle dictionary object with a bunch of info about a fire\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ac0bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_updated_dict(df, shapeRecords, nc_fid, tif_path, save_path, month, year):\n",
    "    d = {}\n",
    "    temp = nc_fid.variables['temperature']\n",
    "    counter = 0\n",
    "    for eyeD in np.unique(df['Id']):\n",
    "        d['fireID'] = eyeD\n",
    "        idx = df[[df['Id'][i] == eyeD and df['Type'][i] == 'FinalArea' for i in range(len(df))]].index  \n",
    "        final_fire_indices = shapeRecords[idx[0]].shape.points\n",
    "        sorted_df = sort_by_id(df, eyeD)\n",
    "        d['Unique Dates'] = sorted_df['IDate'].unique()\n",
    "        M = np.load('C:\\\\Users\\\\nicoc\\\\Desktop\\\\Stanford\\\\OneDrive\\\\OneDrive - Stanford\\\\Courses\\\\CS229\\\\finalproject\\\\data\\\\United_States_Fires\\\\United_States_{year}_Fires\\\\{month}\\\\multi_day\\\\{file}.npy'.format(file = str(eyeD), month = month, year = year))\n",
    "        d['multiDay'] = M\n",
    "        d['IDate'] = shapeRecords[idx[0]].record['IDate']\n",
    "        d['FDate'] = shapeRecords[idx[0]].record['FDate']\n",
    "        a = get_fire_shape_and_discretization(final_fire_indices)\n",
    "        xRange, yRange, xDiff, yDiff = a\n",
    "        d['xRange'] = xRange\n",
    "        d['yRange'] = yRange\n",
    "        d['xDiff'] = xDiff\n",
    "        d['yDiff'] = yDiff\n",
    "        d0 = date(2010, 1, 1)\n",
    "        d1 = d['IDate']\n",
    "        d2 = d['FDate']\n",
    "        long = d['xRange'][0] + (d['xRange'][0] + d['xRange'][1])/2\n",
    "        lat = d['yRange'][0] + (d['yRange'][0] + d['yRange'][1])/2\n",
    "        temp_array = []\n",
    "        for i in range((d2 - d1).days):\n",
    "            long_index = ceil(long)\n",
    "            lat_index = ceil(lat)\n",
    "            day = (d1 - d0).days\n",
    "            temperature = temp[day + i][lat_index][long_index]     \n",
    "            temp_array.append(temperature)\n",
    "            \n",
    "        d['Temperature'] = temp_array\n",
    "        \n",
    "        elevation, top = elevation_func(tif_path, xRange, yRange, xDiff, yDiff)\n",
    "        \n",
    "\n",
    "        d['Elevation Data'] = elevation\n",
    "        d['Topographic Data'] = top\n",
    "        counter += 1\n",
    "        \n",
    "                \n",
    "        print(\"Fire {day} done\".format(day = counter))\n",
    "        \n",
    "        # create a binary pickle file \n",
    "        f = open(\"{path}/{eyeD}.pkl\".format(path = save_path, eyeD = str(eyeD)),\"wb\")\n",
    "        pickle.dump(d,f)\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e49078",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Main:</b> MAIN script to iterate through all of nico's files and create the saved dictionaries\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498af0d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "nc_f = \"C:/Users/nicoc/Downloads/Complete_TAVG_Daily_LatLong1_2010.nc\"  # Your filename\n",
    "tif_path = 'C:\\\\Users\\\\nicoc\\\\Downloads\\\\LF2016_Elev_200_CONUS\\\\Tif\\\\LC16_Elev_200.tif'\n",
    "nc_fid = Dataset(nc_f, 'r')  # Dataset is the class behavior to open the file\n",
    "                            # and create an instance of the ncCDF4 class\n",
    "temp = nc_fid.variables['temperature']\n",
    "parent_path = 'C:\\\\Users\\\\nicoc\\\\Desktop\\\\Stanford\\\\OneDrive\\\\OneDrive - Stanford\\\\Courses\\\\CS229\\\\finalproject\\\\data\\\\United_States_Fires\\\\United_States_2018_Fires\\\\'\n",
    "for subdir, dirs, files in os.walk(parent_path):\n",
    "    for directory in dirs:\n",
    "        '''\n",
    "        if directory not in ['sep']:\n",
    "            continue\n",
    "        '''\n",
    "        \n",
    "        if directory not in ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']:\n",
    "            continue\n",
    "        \n",
    "        print('Currently on {month}'.format(month = directory))\n",
    "        for file in os.listdir(r\"{path}/{month}/\".format(path = subdir, month = directory)): \n",
    "            # check the files which are end with specific extension\n",
    "            if file.endswith(\".shp\"):\n",
    "                # print path name of selected files\n",
    "                shape = shapefile.Reader(\"{path}/{month}/{file_name}\".format(file_name = str(file), path = subdir, month = directory))\n",
    "                shapeRecords = shape.shapeRecords()\n",
    "            if file.endswith(\".dbf\"):\n",
    "                dbf =  Dbf5(\"{path}/{month}/{file_name}\".format(file_name = str(file), month = directory, path = subdir))\n",
    "                df = dbf.to_dataframe()\n",
    "\n",
    "        if not os.path.isdir( \"{path}\\\\{month}\\\\storage\\\\\".format(month = directory, path = subdir)):\n",
    "            os.mkdir(\"{path}\\\\{month}\\\\storage\\\\\".format(month = directory, path = subdir))\n",
    "\n",
    "\n",
    "\n",
    "        generate_updated_dict(df, shapeRecords, nc_fid, tif_path, \"{path}\\\\{month}\\\\storage\\\\\".format(path = subdir, month = directory), directory, year = '2018')\n",
    "\n",
    "        print(\"Saved data for {x0}-{year}!\".format(x0 = directory, year = '2018'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa5cf4c",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Example: </b> Example on how to use the pickle data!\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b79a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\nicoc\\\\Desktop\\\\Stanford\\\\OneDrive\\\\OneDrive - Stanford\\\\Courses\\\\CS229\\\\finalproject\\\\data\\\\United_States_Fires\\\\United_States_2017_Fires\\\\apr\\\\storage\"\n",
    "with open(\"{path}\\\\{id}.pkl\".format(path = path, id =19477533), 'rb') as f:\n",
    "    data = pickle.load(f)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
