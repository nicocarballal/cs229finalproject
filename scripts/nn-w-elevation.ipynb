{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f63f654",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Imports:</b> Common imports for NumPy, MatplotLib, Pandas, and OS </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d444e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import for data generation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d6b612",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>ML Imports:</b> Imports to execute RNN model for sequential data </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa2c43e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "from pyspark import SparkContext\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91efb78",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>nn_train_test() function:</b> \n",
    "    \n",
    "This function takes inputs:\n",
    "    \n",
    "    path --> path to the repository with all your .npy file\n",
    "    n_future --> number of future days of fire you want to predict (will be 1 for us)\n",
    "    n_comp --> number of principal componenents you want PCA to reduce to\n",
    "    n_past --> number of past days you want to consider (we can experiment with this)\n",
    "    \n",
    "Outputs:\n",
    "    \n",
    "    input_dim is set to a 1-D array of 256 ^ 2 for now! \n",
    "    x_train --> x_train in format (batch_size, timesteps, input_dim)\n",
    "    y_train --> training data in format (batch_size, input_dim)\n",
    "    pca_array --> an array of all of the PCA's done to the x_training data in a row. This is useful when computing the \n",
    "    inverse of the results of your neural net!\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be2cf855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_train_test(path, n_past, n_comp, n_future = 1):\n",
    "    x_train_list = []\n",
    "    y_train_list = []\n",
    "    count = 0\n",
    "    pca_array = []\n",
    "    for file in os.listdir(r\"{path}\".format(path = path)):\n",
    "        if os.path.getsize(\"{path}\\\\{file}\".format(path = path, file = file)) < 10000000:\n",
    "            continue\n",
    "        with open(\"{path}\\\\{file}\".format(path = path, file = file), 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        training_fire = data['multiDay']\n",
    "        elevation_data = data['Elevation Data'][:-1,:-1]\n",
    "        elev_shape = np.array(elevation_data.shape)\n",
    "        elevation_fire = np.zeros((256, 256))\n",
    "        shape = np.array(training_fire.shape) \n",
    "        if shape[0] < n_past + n_future:\n",
    "            continue\n",
    "        standard_fire = np.zeros((len(training_fire), 256, 256))    \n",
    "        if shape[1] > 255 or shape[2] > 255:\n",
    "            standard_fire[:shape[0], :min(256, shape[1]), :min(256, shape[2])] = training_fire[:, :256, :256]           \n",
    "        else: \n",
    "            standard_fire[:shape[0], :shape[1], :shape[2]] = training_fire     \n",
    "            \n",
    "        if elev_shape[0] > 255 or elev_shape[1] > 255:\n",
    "            elevation_fire[:min(256, elev_shape[0]), :min(256, elev_shape[1])] = elevation_data[:256, :256]\n",
    "        else:\n",
    "            elevation_fire[:min(256, elev_shape[0]), :min(256, elev_shape[1])] = elevation_data\n",
    "        n_comp = 5\n",
    "        shape = standard_fire.shape\n",
    "        pca_fire = np.zeros((shape[0], shape[1], n_comp))\n",
    "        j = 0\n",
    "        pca_dict = {}\n",
    "        for day in standard_fire:\n",
    "            pca = decomposition.PCA(n_components=n_comp)\n",
    "            #plt.matshow(day)\n",
    "            #np.random.seed(134)           \n",
    "            day = pca.fit_transform(day)                       \n",
    "            #plt.matshow(day)            \n",
    "            #print('------')            \n",
    "            #np.random.seed(134)            \n",
    "            pca_fire[j] = day\n",
    "            \n",
    "            pca_dict[j] = pca   \n",
    "            j += 1\n",
    "        \n",
    "        pca_elevation = decomposition.PCA(n_components = n_comp)\n",
    "        pca_elev = pca_elevation.fit_transform(elevation_fire)\n",
    "        elev_shape = np.array(pca_elev.shape)\n",
    "        pca_elev = np.reshape(pca_elev, (elev_shape[0] * elev_shape[1]))\n",
    "        \n",
    "        shape = pca_fire.shape    \n",
    "        pca_fire = np.reshape(pca_fire, (shape[0], shape[1] * shape[2]))\n",
    "        x_train = np.zeros((n_past, pca_fire.shape[1]))\n",
    "        y_train = np.zeros((pca_fire.shape[1]))\n",
    "        for i in range(0 , len(pca_fire) - n_future - n_past + 1):\n",
    "            prev_fires_and_elevation = np.vstack((pca_fire[i : i + n_past], pca_elev))\n",
    "            x_train_list.append(prev_fires_and_elevation)\n",
    "            y_train_list.append(pca_fire[i + n_past: i + n_past + n_future])\n",
    "            pca_array.append(pca_dict[i + n_past])\n",
    "        print(data['fireID'])\n",
    "        print(len(x_train_list), len(y_train_list), len(pca_array))\n",
    "    x_train = np.array(x_train_list)\n",
    "    y_train = np.array(y_train_list)  \n",
    "    \n",
    "    x_train = np.reshape(x_train, (x_train.shape[0],  x_train.shape[2], x_train.shape[1]))\n",
    "    y_train = np.reshape(y_train, (y_train.shape[0], y_train.shape[2]))    \n",
    "    print(x_train.shape, y_train.shape, len(pca_array))\n",
    "    return x_train, y_train, pca_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf4b09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_train_test2(path, n_past, n_comp, n_future = 1):\n",
    "    x_train_list = []\n",
    "    y_train_list = []\n",
    "    count = 0\n",
    "    pca_array = []\n",
    "    for file in os.listdir(r\"{path}\".format(path = path)):\n",
    "        if os.path.getsize(\"{path}\\\\{file}\".format(path = path, file = file)) < 10000000:\n",
    "            continue\n",
    "        with open(\"{path}\\\\{file}\".format(path = path, file = file), 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        training_fire = data['multiDay']\n",
    "        elevation_data = data['Elevation Data'][:-1,:-1]\n",
    "        elev_shape = np.array(elevation_data.shape)\n",
    "        elevation_fire = np.zeros((256, 256))\n",
    "        shape = np.array(training_fire.shape) \n",
    "        if shape[0] < n_past + n_future:\n",
    "            continue\n",
    "        standard_fire = np.zeros((len(training_fire), 256, 256))    \n",
    "        if shape[1] > 255 or shape[2] > 255:\n",
    "            standard_fire[:shape[0], :min(256, shape[1]), :min(256, shape[2])] = training_fire[:, :256, :256]           \n",
    "        else: \n",
    "            standard_fire[:shape[0], :shape[1], :shape[2]] = training_fire     \n",
    "            \n",
    "        if elev_shape[0] > 255 or elev_shape[1] > 255:\n",
    "            elevation_fire[:min(256, elev_shape[0]), :min(256, elev_shape[1])] = elevation_data[:256, :256]\n",
    "        else:\n",
    "            elevation_fire[:min(256, elev_shape[0]), :min(256, elev_shape[1])] = elevation_data\n",
    "        \n",
    "        pca_fire = standard_fire.reshape((256, 256, len(training_fire)))\n",
    "        pca_elev = elevation_fire\n",
    "        print(pca_fire[0: 0 + 3].shape, pca_elev.shape)\n",
    "        for i in range(0 , len(training_fire) - n_future - n_past + 1):\n",
    "            prev_fires_and_elevation = np.dstack((pca_fire[:, :, i : i + n_past], pca_elev))\n",
    "            \n",
    "            x_train_list.append(pca_fire[:, :, i : i + n_past])\n",
    "            y_train_list.append(pca_fire[:, :, i + n_past: i + n_past + n_future])\n",
    "        print(data['fireID'])\n",
    "        print(len(x_train_list), len(y_train_list))\n",
    "    x_train = np.array(x_train_list)\n",
    "    y_train = np.array(y_train_list)  \n",
    "    \n",
    "    print(x_train.shape, y_train.shape)\n",
    "    \n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[2] * x_train.shape[1], x_train.shape[3]))\n",
    "    y_train = np.reshape(y_train, (y_train.shape[0], y_train.shape[1] * y_train.shape[2]))    \n",
    "    print(x_train.shape, y_train.shape, len(pca_array))\n",
    "    return x_train, y_train, pca_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c221a5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>RNN Inputs:</b> \n",
    "We are declaring below that the number of future days we want to predict is 1, and we can vary the number of past days\n",
    "    we want to predict (I have the default as 3 for now)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b52ec8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_future = 1\n",
    "n_comp = 5\n",
    "n_past = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0195095",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Input Data for Training:</b> \n",
    "    Below, we get the input data from December 2018! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dcba14f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "# We are suppressing print statements and warning messages w/ above line\n",
    "path = \"C:\\\\Users\\\\nico\\\\Desktop\\\\Stanford\\\\OneDrive - Stanford\\\\Courses\\\\CS229\\\\finalproject\\\\data\\\\United_States_Fires\\\\United_States_2018_Fires\\\\dec\\\\storage\"\n",
    "x_train, y_train, pca_array  = nn_train_test2(path, n_past = n_past, n_comp = n_comp, n_future = n_future)\n",
    "#x_train, y_train = nn_train_test2(path, n_past = n_past, n_comp = n_comp, n_future = n_future)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df070103",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Check:</b> \n",
    "    Check the shape of your x_train and y_train data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ce1c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    shape = x_train[i].shape\n",
    "    if shape[2] != 3:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d17163",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Train your RNN:</b> Train your RNN using the training data.\n",
    "    \n",
    "    You might notice a lot of arbitrary values here (these are things we will want to change and test)\n",
    "    - Dropout: High dropout leads to more generalization. Low dropout takes advantage of more data but overfits more easily\n",
    "    - # of hidden layers: Right now, there are 2 hidden layers (+ 1 at the end). We can change this\n",
    "    - # units at hidden layers: Right now, units decrease by 1 at each hidden layer. This is arbitrary and can be changed\n",
    "    - optimizer --> 'adam' works but I don't know what it does\n",
    "    - epochs --> We can raise this above 1 but I don't notice that changing much when I have done so\n",
    "    - batch_size --> Higher batch size leads to more generalization\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d187f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac11a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1da31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53/136 [==========>...................] - ETA: 5:53:16 - loss: 0.0167 - acc: 0.9810"
     ]
    }
   ],
   "source": [
    "# No need to run this if you are loading a model\n",
    "regressor = Sequential()\n",
    "\n",
    "dropout = 0.1\n",
    "regressor.add(tf.keras.layers.Bidirectional(LSTM(units=n_past, return_sequences=True, input_shape = x_train[0].shape)))\n",
    "regressor.add(Dropout(dropout))\n",
    "\n",
    "regressor.add(LSTM(units = n_past-1, return_sequences = True))\n",
    "regressor.add(Dropout(dropout))\n",
    "\n",
    "'''\n",
    "regressor.add(LSTM(units = n_past-2, return_sequences = False))\n",
    "regressor.add(Dropout(dropout))\n",
    "'''\n",
    "'''\n",
    "regressor.add(LSTM(units = n_past, return_sequences = True))\n",
    "regressor.add(Dropout(dropout))\n",
    "'''\n",
    "\n",
    "regressor.add(Dense(units = n_future, activation = 'linear'))\n",
    "\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['acc'])\n",
    "\n",
    "regressor.fit(x_train, y_train, epochs = 1, batch_size = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e0def",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Load pre-trained model:</b> \n",
    "    If you want to load a model instead, use this\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58f01ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model_name = 'my_model_no_scalar' ## CHANGE THIS (e.g. 'my_model') ##\n",
    "regressor = load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8c517b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Save pre-trained model:</b> \n",
    "    If you want to save a model instead, use this\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9725bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'elevation_model'## CHANGE THIS (e.g. 'my_model') ##\n",
    "regressor.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964498a0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Input Data for Testing:</b> \n",
    "    Below, we get the input data from March 2018! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7920cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "path = path = \"C:\\\\Users\\\\nicoc\\\\Desktop\\\\Stanford\\\\OneDrive\\\\OneDrive - Stanford\\\\Courses\\\\CS229\\\\finalproject\\\\data\\\\United_States_Fires\\\\United_States_2017_Fires\\\\nov\\\\storage\"\n",
    "x_test, y_test, pca_array  = nn_train_test2(path, n_past = 3, n_comp = n_comp, n_future =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549acdc0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Check:</b> I've noticed the first dimensions of these sometimes these don't match. They should.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a078aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape, y_test.shape, len(pca_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b915a200",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b> Predict Step:</b> This makes your predictions using your model and reshapes them into a list of 2D arrays\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db13b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#sc = MinMaxScaler(feature_range=(0,1)) This might be useful for making absolute predictions\n",
    "predict_test = regressor.predict(x_test)\n",
    "shape = predict_test.shape\n",
    "nComp = 10\n",
    "predict_test = np.reshape(predict_test, (shape[0], nComp,  shape[1]//nComp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1495ef8d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b> Predict Step:</b> Change the number for test number to see how well your network is doing visually\n",
    "    \n",
    "    Note the pca_array[i].inverse_transform()!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971021de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_number = i = 10\n",
    "d = y_test[i]\n",
    "d = np.reshape(d, (256, 5))\n",
    "plt.matshow(pca_array[i].inverse_transform(d))\n",
    "d = predict_test[i]\n",
    "d = np.reshape(d, (256, 5))\n",
    "plt.matshow(pca_array[i].inverse_transform(d))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
