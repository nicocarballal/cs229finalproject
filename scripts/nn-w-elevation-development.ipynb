{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e28739",
   "metadata": {},
   "source": [
    "This notebook is for development! Use it to try out new strategies :) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6284fcd3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Imports:</b> Common imports for NumPy, MatplotLib, Pandas, and OS </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c47bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import for data generation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4f250",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>ML Imports:</b> Imports to execute RNN model for sequential data </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b788d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "from pyspark import SparkContext\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d6ead9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>nn_train_test() function:</b> \n",
    "    \n",
    "This function creates the train and test sets a little differently. Instead of using pca to reduce dimensionality, it keeps all the data in anticipation of the Neural Net Framework to deal with filtering through it. The d variable allows you to discretize the grid down further as well.\n",
    "    \n",
    "    path --> path to the repository with all your .npy file\n",
    "    n_future --> number of future days of fire you want to predict (will be 1 for us)\n",
    "    n_comp --> Doesn't do anything right now\n",
    "    n_past --> number of past days you want to consider (we can experiment with this)\n",
    "    d --> The size of the discretized fires you want (i.e. d= 32, returns subset of sequences for 32x32 grids)\n",
    "    \n",
    "Outputs:\n",
    "    \n",
    "    input_dim is set to a 1-D array of 256 ^ 2 for now! \n",
    "    x_train --> x_train in format (batch_size, timesteps, input_dim)\n",
    "    y_train --> training data in format (batch_size, input_dim)\n",
    "    pca_array -->  Nothing\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e639e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_train_test(path, n_past, n_comp, n_future = 1, d = 256):\n",
    "    x_train_list = []\n",
    "    y_train_list = []\n",
    "    count = 0\n",
    "    pca_array = []\n",
    "    for file in os.listdir(r\"{path}\".format(path = path)):\n",
    "        if os.path.getsize(\"{path}\\\\{file}\".format(path = path, file = file)) < 10000000:\n",
    "            continue\n",
    "        with open(\"{path}\\\\{file}\".format(path = path, file = file), 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        training_fire = data['multiDay']\n",
    "        elevation_data = data['Elevation Data'][:-1,:-1]\n",
    "        elev_shape = np.array(elevation_data.shape)\n",
    "        elevation_fire = np.zeros((256, 256))\n",
    "        shape = np.array(training_fire.shape) \n",
    "        fire = np.where(training_fire[1] == 1)\n",
    "        x_center, y_center = int(np.median(fire[0])), int(np.median(fire[1]))\n",
    "        if shape[0] < n_past + n_future:\n",
    "            continue\n",
    "        standard_fire = np.zeros((len(training_fire), 256, 256))    \n",
    "        if shape[1] > 255 or shape[2] > 255:\n",
    "\n",
    "\n",
    "            # could not broadcast input array from shape (39,350,325) into shape (39,512,416)\n",
    "            xLow = x_center - 128 \n",
    "            xHi = shape[1] - x_center\n",
    "            yLow = y_center - 128\n",
    "            yHi = shape[2] - y_center\n",
    "            print(xLow, xHi, yLow, yHi)\n",
    "            if shape[1] > 255:\n",
    "                if xLow < 0:\n",
    "                    xHi = x_center + 128 - xLow\n",
    "                    xLow = 0\n",
    "                elif xHi < 128:\n",
    "                    xLow = x_center - 256 + xHi\n",
    "                    xHi = shape[1]\n",
    "                else:\n",
    "                    xLow = x_center - 128\n",
    "                    xHi = x_center + 128\n",
    "            else:\n",
    "                xLow = 0\n",
    "                xHi = shape[1]\n",
    "\n",
    "            if shape[2] > 255:\n",
    "                if yLow < 0:\n",
    "                    yHi = y_center + 128 - yLow\n",
    "                    yLow = 0\n",
    "                elif yHi < 128:\n",
    "                    yLow = y_center - 256 + yHi\n",
    "                    yHi = shape[2]\n",
    "                else:\n",
    "                    yLow = y_center - 128\n",
    "                    yHi = y_center + 128\n",
    "            else:\n",
    "                yLow = 0\n",
    "                yHi = shape[2]\n",
    "            print(xLow, xHi, yLow, yHi)\n",
    "            standard_fire[:shape[0], :min(256, shape[1]), :min(256, shape[2])] = training_fire[:, xLow: xHi, yLow: yHi]   \n",
    "            elevation_fire[:min(256, elev_shape[0]), :min(256, elev_shape[1])] = elevation_data[xLow: xHi, yLow: yHi]\n",
    "        else: \n",
    "            standard_fire[:shape[0], :shape[1], :shape[2]] = training_fire\n",
    "            elevation_fire[:min(256, elev_shape[0]), :min(256, elev_shape[1])] = elevation_data\n",
    "\n",
    "        pca_fire = standard_fire\n",
    "        pca_elev = elevation_fire.reshape((1, 256, 256))\n",
    "        for i in range(0 , len(training_fire) - n_future - n_past + 1):\n",
    "            shape = pca_fire[i : i + n_past].shape\n",
    "            a = np.zeros((shape[0] + 1, shape[1], shape[2]))\n",
    "            a[:3] = pca_fire[i : i + n_past]\n",
    "            a[3:] = pca_elev \n",
    "            for j in np.arange(0, 255, d):\n",
    "                for k in np.arange(0, 255, d):\n",
    "                    x_train_list.append(a[:, j:j+d, k:k+d])\n",
    "                    y_train_list.append(pca_fire[i + n_past: i + n_past + n_future, j:j+d, k:k+d])\n",
    "    \n",
    "    x_train = np.array(x_train_list)\n",
    "    y_train = np.array(y_train_list)  \n",
    "    \n",
    "    #x_train = np.reshape(x_train, (x_train.shape[0],  x_train.shape[2], x_train.shape[1]))\n",
    "    #y_train = np.reshape(y_train, (y_train.shape[0], y_train.shape[2]))    \n",
    "    print(x_train.shape, y_train.shape, len(pca_array))\n",
    "    return x_train, y_train, pca_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098aad49",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>RNN Inputs:</b> \n",
    "We are declaring below that the number of future days we want to predict is 1, and we can vary the number of past days\n",
    "    we want to predict (I have the default as 3 for now)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "176016f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_future = 1\n",
    "n_comp = 10\n",
    "n_past = 3\n",
    "discretization_amount = d = 256 # 256 means we keep the whole fire grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80833767",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Input Data for Training:</b> \n",
    "    Below, we get the input data from December 2018! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78caa976",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "# We are suppressing print statements and warning messages w/ above line\n",
    "path = \"C:\\\\Users\\\\nico\\\\Desktop\\\\Stanford\\\\OneDrive - Stanford\\\\Courses\\\\CS229\\\\finalproject\\\\data\\\\United_States_Fires\\\\United_States_2018_Fires\\\\dec\\\\storage\"  \n",
    "x_train, y_train, pca_array  = nn_train_test(path, n_past = n_past, n_comp = n_comp, n_future = n_future, d = d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a84dfb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((408, 4, 256, 256), (408, 1, 256, 256))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5265e3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Check:</b> \n",
    "    Check the shape of your x_train and y_train data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ed7348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((408, 4, 256, 256), (408, 1, 256, 256))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8fc63d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    This follows the model in https://towardsdatascience.com/wildfire-spreading-modeling-in-alberta-canada-a-trial-using-a-neural-network-with-convlstm-cells-81c1a9f7d410. Their GitHub is at the bottom of the page \n",
    "    \n",
    "<b>Train your RNN:</b> Train your RNN using the training data.\n",
    "    \n",
    "    You might notice a lot of arbitrary values here (these are things we will want to change and test)\n",
    "    - Dropout: High dropout leads to more generalization. Low dropout takes advantage of more data but overfits more easily\n",
    "    - # of hidden layers: Right now, there are 2 hidden layers (+ 1 at the end). We can change this\n",
    "    - # units at hidden layers: Right now, units decrease by 1 at each hidden layer. This is arbitrary and can be changed\n",
    "    - optimizer --> 'adam' works but I don't know what it does\n",
    "    - epochs --> We can raise this above 1 but I don't notice that changing much when I have done so\n",
    "    - batch_size --> Higher batch size leads to more generalization\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef239d9",
   "metadata": {},
   "source": [
    "Reshape your data as needed for the ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0195febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x_train.reshape((int(408 * 256**2/d**2), 4, 1, d, d)), y_train.reshape((int(408 * 256**2/d**2), d*d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1b19fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((408, 4, 256, 256, 1), (408, 256, 256))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ba0d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 31/408 [=>............................] - ETA: 18:10 - loss: 0.0374 - acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "# No need to run this if you are loading a model\n",
    "regressor = Sequential()\n",
    "\n",
    "dropout = 0.1\n",
    "\n",
    "#regressor.add(tf.keras.layers.Masking(mask_value=-9999,input_shape= x_train[0].shape)) \n",
    "regressor.add(tf.keras.layers.ConvLSTM2D(filters = 64, kernel_size = (3,3), return_sequences = True, data_format='channels_first', activation = \"tanh\", input_shape = x_train[0].shape))\n",
    "\n",
    "regressor.add(tf.keras.layers.MaxPool3D(pool_size = (2,2,2)))\n",
    "\n",
    "regressor.add(tf.keras.layers.ConvLSTM2D(filters = 64, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
    "\n",
    "regressor.add(tf.keras.layers.MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "regressor.add(tf.keras.layers.Flatten())\n",
    "\n",
    "regressor.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "regressor.add(tf.keras.layers.Dropout(0.1))\n",
    "\n",
    "regressor.add(tf.keras.layers.Dense(units = 256, activation = 'relu'))\n",
    "\n",
    "regressor.add(tf.keras.layers.Dropout(0.1))\n",
    "\n",
    "\n",
    "regressor.add(tf.keras.layers.Dense(units = 256*256, activation = 'relu'))\n",
    "\n",
    "'''\n",
    "regressor.add(tf.keras.layers.Bidirectional(LSTM(units=n_past, return_sequences=True, input_shape = x_train[0].shape)))\n",
    "regressor.add(Dropout(dropout))\n",
    "\n",
    "regressor.add(LSTM(units = n_past-1, return_sequences = True))\n",
    "regressor.add(Dropout(dropout))\n",
    "\n",
    "regressor.add(LSTM(units = n_past-2, return_sequences = False))\n",
    "regressor.add(Dropout(dropout))\n",
    "\n",
    "regressor.add(LSTM(units = n_past, return_sequences = True))\n",
    "regressor.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "regressor.add(Dense(units = n_future, activation = 'linear'))\n",
    "'''\n",
    "\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['acc'])\n",
    "\n",
    "regressor.fit(x_train, y_train, epochs = 5, batch_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f3f52a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "This follows the general layout of https://keras.io/examples/vision/conv_lstm/. I haven't had much success with it\n",
    "    \n",
    "<b>Train your RNN:</b> Train your RNN using the training data.\n",
    "    \n",
    "    You might notice a lot of arbitrary values here (these are things we will want to change and test)\n",
    "    - Dropout: High dropout leads to more generalization. Low dropout takes advantage of more data but overfits more easily\n",
    "    - # of hidden layers: Right now, there are 2 hidden layers (+ 1 at the end). We can change this\n",
    "    - # units at hidden layers: Right now, units decrease by 1 at each hidden layer. This is arbitrary and can be changed\n",
    "    - optimizer --> 'adam' works but I don't know what it does\n",
    "    - epochs --> We can raise this above 1 but I don't notice that changing much when I have done so\n",
    "    - batch_size --> Higher batch size leads to more generalization\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "4838d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x_train.reshape((int(408 * 256**2/d**2), 4, d, d, 1)), y_train.reshape((int(408 * 256**2/d**2), d, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to run this if you are loading a model\n",
    "regressor = Sequential()\n",
    "\n",
    "dropout = 0.1\n",
    "# Construct the input layer with no definite frame size.\n",
    "inp = tf.keras.layers.Input(shape=(None, *x_train.shape[2:]))\n",
    "#regressor.add(tf.keras.layers.Masking(mask_value=-9999,input_shape= x_train[0].shape)) \n",
    "x = tf.keras.layers.ConvLSTM2D(filters = 64, kernel_size = (5,5), padding=\"same\", return_sequences = True, activation = \"relu\")(inp)\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.ConvLSTM2D(\n",
    "    filters=64,\n",
    "    kernel_size=(3, 3),\n",
    "    padding=\"same\",\n",
    "    return_sequences=True,\n",
    "    activation=\"relu\",\n",
    ")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.ConvLSTM2D(\n",
    "    filters=64,\n",
    "    kernel_size=(1, 1),\n",
    "    padding=\"same\",\n",
    "    return_sequences=True,\n",
    "    activation=\"relu\",\n",
    ")(x)\n",
    "x = tf.keras.layers.ConvLSTM2D(\n",
    "    filters=1,\n",
    "    kernel_size=(1, 1),\n",
    "    padding=\"same\",\n",
    "    return_sequences=True,\n",
    "    activation=\"relu\",\n",
    ")(x)\n",
    "\n",
    "'''\n",
    "x = tf.keras.layers.Conv3D(\n",
    "    filters=1, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\"\n",
    ")(x)\n",
    "'''\n",
    "\n",
    "model = tf.keras.models.Model(inp, x)\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.MeanAbsoluteError(), optimizer=tf.keras.optimizers.Adam(),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=1,\n",
    "    epochs=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d3f600",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Load pre-trained model:</b> \n",
    "    If you want to load a model instead, use this\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "530f10b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model_name = 'cnn_lstm_1' ## CHANGE THIS (e.g. 'my_model') ##\n",
    "regressor = load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b61cb40",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Save pre-trained model:</b> \n",
    "    If you want to save a model instead, use this\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "908cd644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_lstm_keras_2\\assets\n"
     ]
    }
   ],
   "source": [
    "model_name = 'cnn_lstm_keras_2'## CHANGE THIS (e.g. 'my_model') ##\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dbe01f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Input Data for Testing:</b> \n",
    "    Below, we get the input data from March 2018! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "0c05eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "path = path = \"C:\\\\Users\\\\nico\\\\Desktop\\\\Stanford\\\\OneDrive - Stanford\\\\Courses\\\\CS229\\\\finalproject\\\\data\\\\United_States_Fires\\\\United_States_2018_Fires\\\\nov\\\\storage\"\n",
    "x_test, y_test, pca_array  = nn_train_test(path, n_past = 3, n_comp = n_comp, n_future =1, d = d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f40225d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Check:</b> I've noticed the first dimensions of these sometimes these don't match. They should.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "577fa0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087bb6ec",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b> Predict Step:</b> This makes your predictions using your model and reshapes them into a list of 2D arrays\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "e5a41234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "predict_test = regressor.predict(x_test)\n",
    "p = predict_test\n",
    "shape = predict_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
