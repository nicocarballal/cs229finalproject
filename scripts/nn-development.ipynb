{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Imports:</b> Common imports for NumPy, MatplotLib, Pandas, and OS </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import for data generation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>ML Imports:</b> Imports to execute RNN model for sequential data </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "from pyspark import SparkContext\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>nn_train_test() function:</b> \n",
    "    \n",
    "This function takes inputs:\n",
    "    \n",
    "    path --> path to the repository with all your .npy file\n",
    "    n_future --> number of future days of fire you want to predict (will be 1 for us)\n",
    "    n_comp --> number of principal componenents you want PCA to reduce to\n",
    "    n_past --> number of past days you want to consider (we can experiment with this)\n",
    "    \n",
    "Outputs:\n",
    "    \n",
    "    input_dim is set to a 1-D array of 256 ^ 2 for now! \n",
    "    x_train --> x_train in format (batch_size, timesteps, input_dim)\n",
    "    y_train --> training data in format (batch_size, input_dim)\n",
    "    pca_array --> an array of all of the PCA's done to the x_training data in a row. This is useful when computing the \n",
    "    inverse of the results of your neural net!\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_train_test(path, n_past, n_comp, n_future = 1):\n",
    "    x_train_list = []\n",
    "    y_train_list = []\n",
    "    count = 0\n",
    "    pca_array = []\n",
    "    for file in os.listdir(r\"{path}\".format(path = path)):\n",
    "        if os.path.getsize(\"{path}\\\\{file}\".format(path = path, file = file)) < 100000:\n",
    "            continue\n",
    "        training_fire = np.load(\"{path}\\\\{file}\".format(path = path, file = file))\n",
    "        shape = np.array(training_fire.shape) \n",
    "        if shape[0] < n_past + n_future:\n",
    "            continue\n",
    "        standard_fire = np.zeros((len(training_fire), 256, 256))    \n",
    "        if shape[1] > 255 or shape[2] > 255:\n",
    "            standard_fire[:shape[0], :min(256, shape[1]), :min(256, shape[2])] = training_fire[:, :256, :256]\n",
    "        else: \n",
    "            standard_fire[:shape[0], :shape[1], :shape[2]] = training_fire     \n",
    "        n_comp = 5\n",
    "        shape = standard_fire.shape\n",
    "        pca_fire = np.zeros((shape[0], shape[1], n_comp))\n",
    "        j = 0\n",
    "        pca_dict = {}\n",
    "        for day in standard_fire:\n",
    "            pca = decomposition.PCA(n_components=n_comp)\n",
    "            '''\n",
    "            np.random.seed(134)\n",
    "            print(np.random.choice(day.flatten(), 100))\n",
    "            b = StandardScaler()\n",
    "            b.fit(day)\n",
    "            day= b.fit_transform(day)\n",
    "            np.random.seed(134)\n",
    "            print(np.random.choice(day.flatten(), 100))\n",
    "            print('------')\n",
    "            '''\n",
    "            #plt.matshow(day)\n",
    "            np.random.seed(134)           \n",
    "            day = pca.fit_transform(day)                       \n",
    "            #plt.matshow(day)            \n",
    "            day3 = pca.inverse_transform(day)            \n",
    "            #plt.matshow(day3)\n",
    "            #print('------')            \n",
    "            np.random.seed(134)            \n",
    "            pca_fire[j] = day\n",
    "            pca_dict[j] = pca    \n",
    "            j += 1\n",
    "        shape = pca_fire.shape    \n",
    "        pca_fire = np.reshape(pca_fire, (shape[0], shape[1] * shape[2]))\n",
    "        x_train = np.zeros((n_past, pca_fire.shape[1]))\n",
    "        y_train = np.zeros((pca_fire.shape[1]))\n",
    "        for i in range(0 , len(pca_fire) - n_future - n_past + 1):\n",
    "            x_train_list.append(pca_fire[i : i + n_past])\n",
    "            y_train_list.append(pca_fire[i + n_past: i + n_past + n_future])\n",
    "            pca_array.append(pca_dict[i + n_past])\n",
    "        print(len(x_train_list), len(y_train_list), len(pca_array))\n",
    "    x_train = np.array(x_train_list)\n",
    "    y_train = np.array(y_train_list)  \n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0],  x_train.shape[2], x_train.shape[1]))\n",
    "    y_train = np.reshape(y_train, (y_train.shape[0], y_train.shape[2]))    \n",
    "    print(x_train.shape, y_train.shape, len(pca_array))\n",
    "    return x_train, y_train, pca_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>RNN Inputs:</b> \n",
    "We are declaring below that the number of future days we want to predict is 1, and we can vary the number of past days\n",
    "    we want to predict (I have the default as 3 for now)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_future = 1\n",
    "n_comp = 5\n",
    "n_past = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Input Data for Training:</b> \n",
    "    Below, we get the input data from December 2018! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# We are suppressing print statements and warning messages w/ above line\n",
    "path = \"C:\\\\Users\\\\nicoc\\\\Desktop\\\\Stanford\\\\OneDrive\\\\OneDrive - Stanford\\\\Courses\\\\CS229\\\\finalproject\\\\data\\\\United_States_Fires\\\\United_States_2018_Fires\\\\dec\\\\multi_day\"\n",
    "x_train, y_train, pca_array  = nn_train_test(path, n_past = n_past, n_comp = n_comp, n_future = n_future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Check:</b> \n",
    "    Check the shape of your x_train and y_train data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Train your RNN:</b> Train your RNN using the training data.\n",
    "    \n",
    "    You might notice a lot of arbitrary values here (these are things we will want to change and test)\n",
    "    - Dropout: High dropout leads to more generalization. Low dropout takes advantage of more data but overfits more easily\n",
    "    - # of hidden layers: Right now, there are 2 hidden layers (+ 1 at the end). We can change this\n",
    "    - # units at hidden layers: Right now, units decrease by 1 at each hidden layer. This is arbitrary and can be changed\n",
    "    - optimizer --> 'adam' works but I don't know what it does\n",
    "    - epochs --> We can raise this above 1 but I don't notice that changing much when I have done so\n",
    "    - batch_size --> Higher batch size leads to more generalization\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to run this if you are loading a model\n",
    "regressor = Sequential()\n",
    "\n",
    "dropout = 0.1\n",
    "regressor.add(tf.keras.layers.Bidirectional(LSTM(units=n_past, return_sequences=True, input_shape = x_train[0].shape)))\n",
    "regressor.add(Dropout(dropout))\n",
    "\n",
    "regressor.add(LSTM(units = n_past - 1, return_sequences = True))\n",
    "regressor.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "regressor.add(LSTM(units = n_past - 2, return_sequences = True))\n",
    "regressor.add(Dropout(dropout))\n",
    "'''\n",
    "regressor.add(LSTM(units = n_past, return_sequences = True))\n",
    "regressor.add(Dropout(dropout))\n",
    "'''\n",
    "\n",
    "regressor.add(Dense(units = n_future, activation = 'linear'))\n",
    "\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['acc'])\n",
    "\n",
    "regressor.fit(x_train, y_train, epochs = 11, batch_size = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Load pre-trained model:</b> \n",
    "    If you want to load a model instead, use this\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model_name = 'my_model_no_scalar' ## CHANGE THIS (e.g. 'my_model') ##\n",
    "regressor = load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Save pre-trained model:</b> \n",
    "    If you want to save a model instead, use this\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ## CHANGE THIS (e.g. 'my_model') ##\n",
    "regressor.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Input Data for Testing:</b> \n",
    "    Below, we get the input data from March 2018! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "path = \"C:\\\\Users\\\\nico\\\\Desktop\\\\Stanford\\\\OneDrive - Stanford\\\\Courses\\\\CS229\\\\finalproject\\\\data\\\\United_States_Fires\\\\United_States_2018_Fires\\\\dec\\\\multi_day\"\n",
    "x_test, y_test, pca_array  = nn_train_test(path, n_past = 3, n_comp = n_comp, n_future =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Check:</b> I've noticed the first dimensions of these sometimes these don't match. They should.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape, y_test.shape, len(pca_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b> Predict Step:</b> This makes your predictions using your model and reshapes them into a list of 2D arrays\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#sc = MinMaxScaler(feature_range=(0,1)) This might be useful for making absolute predictions\n",
    "predict_test = regressor.predict(x_test)\n",
    "shape = predict_test.shape\n",
    "nComp = 10\n",
    "predict_test = np.reshape(predict_test, (shape[0], nComp,  shape[1]//nComp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b> Predict Step:</b> Change the number for test number to see how well your network is doing visually\n",
    "    \n",
    "    Note the pca_array[i].inverse_transform()!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_number = i = 100\n",
    "d = y_test[i]\n",
    "d = np.reshape(d, (256, 5))\n",
    "plt.matshow(pca_array[i].inverse_transform(d))\n",
    "d = predict_test[i]\n",
    "d = np.reshape(d, (256, 5))\n",
    "plt.matshow(pca_array[i].inverse_transform(d))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
